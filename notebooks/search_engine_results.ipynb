{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import DanishStemmer\n",
    "from textblob import TextBlob\n",
    "import lemmy\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '2020-02-26_2020-03-26_nodups_9k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Processed Dataframe\n",
      "Loading TFIDF distances\n",
      "CPU times: user 1min, sys: 3.53 s, total: 1min 3s\n",
      "Wall time: 1min 5s\n",
      "Loading BERT distances\n",
      "CPU times: user 1.11 ms, sys: 32.4 ms, total: 33.5 ms\n",
      "Wall time: 49.1 ms\n",
      "\n",
      " All datasets loaded.\n"
     ]
    }
   ],
   "source": [
    "base = os.path.abspath('../')\n",
    "\n",
    "def outname(name):\n",
    "    return os.path.basename(dataset_name).split('.')[0] + name\n",
    "    \n",
    "outname_tfidf = outname('_distances_tfidf.csv')\n",
    "outname_bert = outname('_encodings_bert.pt')\n",
    "outname_df = outname('_preprocessed_df.csv')\n",
    "\n",
    "print('Loading Processed Dataframe')\n",
    "df = pd.read_csv(f'{base}/data/processed/{outname_df}', index_col=0)\n",
    "\n",
    "print('Loading TFIDF distances')\n",
    "%time tfidf = pd.read_csv( f'{base}/data/processed/{outname_tfidf}', index_col=0)\n",
    "\n",
    "print('Loading BERT distances')\n",
    "## It is not in Tensor format, but rather numpy array\n",
    "# bert = pd.read_csv(f'{base}/data/processed/{outname_bert}', index_col=0)\n",
    "%time bert = torch.load(f'{base}/data/processed/{outname_bert}')\n",
    "\n",
    "print('\\n All datasets loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10140, 8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## notice the corpus and title_processed\n",
    "df.head(5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = str(text).lower().strip()\n",
    "\n",
    "    # caveat: this might conflict with the english text\n",
    "    da_stop_words = stopwords.words('danish')\n",
    "    stemmer = DanishStemmer()\n",
    "    lemmatizer = lemmy.load(\"da\")\n",
    "\n",
    "    # remove plurals\n",
    "    textblob = TextBlob(text)\n",
    "    singles = [stemmer.stem(word) for word in textblob.words]\n",
    "\n",
    "    # remove danish stopwords\n",
    "    no_stop_words = [word for word in singles if word not in da_stop_words]\n",
    "\n",
    "    # join text so it can be lemmatized\n",
    "    joined_text = \" \".join(no_stop_words)\n",
    "\n",
    "    # lemmatization\n",
    "    final_text = lemmatizer.lemmatize(\"\", joined_text)\n",
    "\n",
    "    return final_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEARCH QUERY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'Børne' \n",
    "# search query = 'pædagog skov' # Bert is best, but not great overall\n",
    "# search_query = 'kok' # slighly better than Jobindex\n",
    "# search_query = 'læge neuropædiatri' # BERT exceeds\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct custom search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIRECT RESULTS: 39 \n",
      "\n",
      "Koordinatorer til Red Barnets Familieoplevelsesklub i Aarhus\n",
      "Koordinatorer til Red Barnets Familieoplevelsesklub i Aarhus\n",
      "Pædagog til vores dejlige vuggestue - HOKUS! POKUS! BARNET I FOKUS!\n",
      "Pædagog til vuggestue i Barndommens Land (barselsvikariat)\n",
      "CSV søger ny skolesynskonsulent til Københavns blinde og svagtseende skolebørn\n",
      "Bliv frivillig i Red Barnet Odenses genbrugsbutik\n",
      "Bliv frivillig i Red Barnet Odenses genbrugsbutik\n",
      "Bliv frivillig i Red Barnet Odenses genbrugsbutik\n",
      "pædagog som brænder for vuggestuebørn\n",
      "Har du hvad der skal til for at blive medleder i Red Barnet Odense?\n",
      "CPU times: user 25.1 ms, sys: 3.32 ms, total: 28.5 ms\n",
      "Wall time: 26.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def find_direct_results(search_query):\n",
    "    matching_entries = [df['title_processed'].index[df['title_processed'].str.contains(word, case=False)]\n",
    "                        .values for word in search_query.split()]\n",
    "    return list(set(matching_entries[0]).intersection(*matching_entries))\n",
    "\n",
    "def print_direct_search_results(direct_results):\n",
    "    agg_direct_results_indexes = []\n",
    "    print('DIRECT RESULTS:', len(direct_results), '\\n')\n",
    "    for index, result in enumerate(direct_results[:k]):\n",
    "        print(df['title'][result])\n",
    "        agg_direct_results_indexes.append(result)\n",
    "#     return agg_direct_results_indexes\n",
    "\n",
    "direct_results = find_direct_results(preprocess_text(search_query))\n",
    "print_direct_search_results(direct_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF: Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "\n",
      "Koordinatorer til Red Barnets Familieoplevelsesklub i Aarhus\n",
      "Koordinatorer til Red Barnets Familieoplevelsesklub i Aarhus\n",
      "Vil du skabe gode oplevelser for børn i vores familieoplevelsesklub på Nørrebro?\n",
      "Bliv koordinator i klub med fokus på friluftsliv og oplevelser i naturen\n",
      "FAMILIEOPLEVELSESKLUB - Giv sårbare familier i Odense oplevelser for livet\n",
      "FAMILIEOPLEVELSESKLUB - Giv sårbare familier i Odense oplevelser for livet\n",
      "FAMILIEOPLEVELSESKLUB - Giv sårbare familier i Odense oplevelser for livet\n",
      "Hjælp et udsat barn i Århus ind i et godt og aktivt fritidsliv\n",
      "Hjælp et udsat barn i Århus ind i et godt og aktivt fritidsliv\n",
      "Red Barnet Aarhus søger frivillige til vores familielejr i uge 31\n",
      "CPU times: user 8.39 s, sys: 150 ms, total: 8.54 s\n",
      "Wall time: 8.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def recommendations(data, results):\n",
    "    sorted_results = []\n",
    "    recommendation_indexes = []\n",
    "    for result in results:\n",
    "        sorted_distances = data[str(result)].sort_values().iteritems()\n",
    "        \n",
    "        for item_index, item_value in enumerate(sorted_distances):\n",
    "            index, distance = item_value\n",
    "            sorted_results.append({\n",
    "                'item_index': index,\n",
    "                'distance': distance,\n",
    "                'title': df['title'][index]\n",
    "            })\n",
    "            \n",
    "    agg_sorted_indexes = [x['item_index'] for x in sorted_results]\n",
    "    ## removing direct_results for all results\n",
    "    recommendation_indexes = [x for x in agg_sorted_indexes if x not in results]\n",
    "        \n",
    "#     return recommendation_indexes\n",
    "    return agg_sorted_indexes\n",
    "\n",
    "def display_results(data, name, direct_results):\n",
    "    print (f'{name}\\n')\n",
    "    for index, recommendation in enumerate(recommendations(data=data, results=direct_results)[:k]):\n",
    "        print(df['title'][recommendation])\n",
    "\n",
    "def get_tfidf_recommendations(query):\n",
    "    if len(direct_results) == 0:\n",
    "        return None\n",
    "    display_results(data=tfidf, name='TFIDF', direct_results=direct_results)\n",
    "\n",
    "get_tfidf_recommendations(query=search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n",
      "\n",
      "Børneguitar SoundStoreXL.com A/S\n",
      "Børnehaveleder Gilleleje\n",
      "Ungdomsleder Frederiksberg C\n",
      "Pædagog til 11-årig pige Frederikssund\n",
      "Centerleder til børne- og ungeområdet Haslev\n",
      "Hjælper til dreng på 13 år København S\n",
      "Børneinstrument pakker SoundStoreXL.com A/S\n",
      "Hjælper til højtbegavet 10-årig dreng Kgs. Lyngby\n",
      "Pædagog til børnehave Viborg\n",
      "Pædagog til børnehave Viborg\n",
      "CPU times: user 665 ms, sys: 20.4 ms, total: 685 ms\n",
      "Wall time: 710 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def bert_results(bert_embeddings, query):\n",
    "    embedded_query = embedder.encode(query, convert_to_tensor=True)\n",
    "    sims = util.pytorch_cos_sim(embedded_query, bert)[0]\n",
    "\n",
    "    results = sorted(range(len(sims)), key=lambda x: sims[x], reverse=True)[:k]\n",
    "    ## removing direct_results for all results\n",
    "    filtered_results = [x for x in results if x not in direct_results]\n",
    "    return results\n",
    "\n",
    "\n",
    "print (f'BERT\\n')\n",
    "for recommendation in bert_results(bert_embeddings=bert, query=search_query):\n",
    "    print(df['title'][recommendation], df['location'][recommendation]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Processed Dataframe...\n",
      "\n",
      "Done.\n",
      "(273585, 8)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'jobindex_2019_03_26-2020_03_26'\n",
    "\n",
    "outname_df_big = outname('_preprocessed_df.csv')\n",
    "\n",
    "print('Loading Processed Dataframe...')\n",
    "df_big = pd.read_csv(f'{base}/data/processed/{outname_df_big}', index_col=0)\n",
    "print('\\nDone.')\n",
    "print(df_big.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 ms, sys: 765 ms, total: 767 ms\n",
      "Wall time: 790 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([273585, 768])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outname_bert_big = outname('_encodings_bert.pt')\n",
    "bert_big = torch.load(f'{base}/data/processed/{outname_bert_big}')\n",
    "bert_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurist med speciale i fast ejendom til Københavns Ejendomme og Indkøb\n",
      "Jurist med kendskab til erhvervslejeret og fast ejendom til Udlejning i Københavns Ejendomme & Indkøb\n",
      "Jurist med kendskab til erhvervslejeret og fast ejendom til Udlejning hos Københavns Ejendomme & Indkøb\n",
      "Advokatfuldmægtige til København\n",
      "Erfaren ejendomsadministrator søges til advokatvirksomhed i København\n",
      "Advokat/jurist med kendskab til offentlig ret og fast ejendom generelt til afdelingen Udlejning i Københavns Kommune\n",
      "Jurist med kompetencer inden for ejendomsjura til Københavns Ejendomme og Indkøb\n",
      "Jurist med kompetencer inden for ejendomsjura til Københavns Ejendomme og Indkøb\n",
      "Jurist med kompetencer inden for ejendomsjura til Københavns Ejendomme og Indkøb\n",
      "Sagsbehandlere inden for ejendomsskat til Københavns Kommune\n",
      "CPU times: user 25 s, sys: 913 ms, total: 25.9 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedded_query= embedder.encode('advokat til ejendomme i Copenhagen', convert_to_tensor=True)\n",
    "sims_big = util.pytorch_cos_sim(embedded_query, bert_big)[0]\n",
    "results_bert = sorted(range(len(sims_big)), key=lambda x: sims_big[x], reverse=True)[:k]\n",
    "\n",
    "\n",
    "for recommendation in results_bert:\n",
    "    print(df_big['title'][recommendation]) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
